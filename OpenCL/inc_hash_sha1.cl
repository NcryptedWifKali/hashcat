
// important notes on this:
// input buf unused bytes needs to be set to zero
// input buf need to be in algorithm native byte order (md5 = LE, sha1 = BE, etc)
// input buf need to be 64 byte aligned when usin sha1_update()

typedef struct sha1_ctx
{
  u32x h[5];

  u32x w0[4];
  u32x w1[4];
  u32x w2[4];
  u32x w3[4];

  int  len;

} sha1_ctx_t;

void sha1_transform (const u32x w0[4], const u32x w1[4], const u32x w2[4], const u32x w3[4], u32x digest[5])
{
  u32x a = digest[0];
  u32x b = digest[1];
  u32x c = digest[2];
  u32x d = digest[3];
  u32x e = digest[4];

  u32x w0_t = w0[0];
  u32x w1_t = w0[1];
  u32x w2_t = w0[2];
  u32x w3_t = w0[3];
  u32x w4_t = w1[0];
  u32x w5_t = w1[1];
  u32x w6_t = w1[2];
  u32x w7_t = w1[3];
  u32x w8_t = w2[0];
  u32x w9_t = w2[1];
  u32x wa_t = w2[2];
  u32x wb_t = w2[3];
  u32x wc_t = w3[0];
  u32x wd_t = w3[1];
  u32x we_t = w3[2];
  u32x wf_t = w3[3];

  #undef K
  #define K SHA1C00

  SHA1_STEP (SHA1_F0o, a, b, c, d, e, w0_t);
  SHA1_STEP (SHA1_F0o, e, a, b, c, d, w1_t);
  SHA1_STEP (SHA1_F0o, d, e, a, b, c, w2_t);
  SHA1_STEP (SHA1_F0o, c, d, e, a, b, w3_t);
  SHA1_STEP (SHA1_F0o, b, c, d, e, a, w4_t);
  SHA1_STEP (SHA1_F0o, a, b, c, d, e, w5_t);
  SHA1_STEP (SHA1_F0o, e, a, b, c, d, w6_t);
  SHA1_STEP (SHA1_F0o, d, e, a, b, c, w7_t);
  SHA1_STEP (SHA1_F0o, c, d, e, a, b, w8_t);
  SHA1_STEP (SHA1_F0o, b, c, d, e, a, w9_t);
  SHA1_STEP (SHA1_F0o, a, b, c, d, e, wa_t);
  SHA1_STEP (SHA1_F0o, e, a, b, c, d, wb_t);
  SHA1_STEP (SHA1_F0o, d, e, a, b, c, wc_t);
  SHA1_STEP (SHA1_F0o, c, d, e, a, b, wd_t);
  SHA1_STEP (SHA1_F0o, b, c, d, e, a, we_t);
  SHA1_STEP (SHA1_F0o, a, b, c, d, e, wf_t);
  w0_t = rotl32 ((wd_t ^ w8_t ^ w2_t ^ w0_t), 1u); SHA1_STEP (SHA1_F0o, e, a, b, c, d, w0_t);
  w1_t = rotl32 ((we_t ^ w9_t ^ w3_t ^ w1_t), 1u); SHA1_STEP (SHA1_F0o, d, e, a, b, c, w1_t);
  w2_t = rotl32 ((wf_t ^ wa_t ^ w4_t ^ w2_t), 1u); SHA1_STEP (SHA1_F0o, c, d, e, a, b, w2_t);
  w3_t = rotl32 ((w0_t ^ wb_t ^ w5_t ^ w3_t), 1u); SHA1_STEP (SHA1_F0o, b, c, d, e, a, w3_t);

  #undef K
  #define K SHA1C01

  w4_t = rotl32 ((w1_t ^ wc_t ^ w6_t ^ w4_t), 1u); SHA1_STEP (SHA1_F1, a, b, c, d, e, w4_t);
  w5_t = rotl32 ((w2_t ^ wd_t ^ w7_t ^ w5_t), 1u); SHA1_STEP (SHA1_F1, e, a, b, c, d, w5_t);
  w6_t = rotl32 ((w3_t ^ we_t ^ w8_t ^ w6_t), 1u); SHA1_STEP (SHA1_F1, d, e, a, b, c, w6_t);
  w7_t = rotl32 ((w4_t ^ wf_t ^ w9_t ^ w7_t), 1u); SHA1_STEP (SHA1_F1, c, d, e, a, b, w7_t);
  w8_t = rotl32 ((w5_t ^ w0_t ^ wa_t ^ w8_t), 1u); SHA1_STEP (SHA1_F1, b, c, d, e, a, w8_t);
  w9_t = rotl32 ((w6_t ^ w1_t ^ wb_t ^ w9_t), 1u); SHA1_STEP (SHA1_F1, a, b, c, d, e, w9_t);
  wa_t = rotl32 ((w7_t ^ w2_t ^ wc_t ^ wa_t), 1u); SHA1_STEP (SHA1_F1, e, a, b, c, d, wa_t);
  wb_t = rotl32 ((w8_t ^ w3_t ^ wd_t ^ wb_t), 1u); SHA1_STEP (SHA1_F1, d, e, a, b, c, wb_t);
  wc_t = rotl32 ((w9_t ^ w4_t ^ we_t ^ wc_t), 1u); SHA1_STEP (SHA1_F1, c, d, e, a, b, wc_t);
  wd_t = rotl32 ((wa_t ^ w5_t ^ wf_t ^ wd_t), 1u); SHA1_STEP (SHA1_F1, b, c, d, e, a, wd_t);
  we_t = rotl32 ((wb_t ^ w6_t ^ w0_t ^ we_t), 1u); SHA1_STEP (SHA1_F1, a, b, c, d, e, we_t);
  wf_t = rotl32 ((wc_t ^ w7_t ^ w1_t ^ wf_t), 1u); SHA1_STEP (SHA1_F1, e, a, b, c, d, wf_t);
  w0_t = rotl32 ((wd_t ^ w8_t ^ w2_t ^ w0_t), 1u); SHA1_STEP (SHA1_F1, d, e, a, b, c, w0_t);
  w1_t = rotl32 ((we_t ^ w9_t ^ w3_t ^ w1_t), 1u); SHA1_STEP (SHA1_F1, c, d, e, a, b, w1_t);
  w2_t = rotl32 ((wf_t ^ wa_t ^ w4_t ^ w2_t), 1u); SHA1_STEP (SHA1_F1, b, c, d, e, a, w2_t);
  w3_t = rotl32 ((w0_t ^ wb_t ^ w5_t ^ w3_t), 1u); SHA1_STEP (SHA1_F1, a, b, c, d, e, w3_t);
  w4_t = rotl32 ((w1_t ^ wc_t ^ w6_t ^ w4_t), 1u); SHA1_STEP (SHA1_F1, e, a, b, c, d, w4_t);
  w5_t = rotl32 ((w2_t ^ wd_t ^ w7_t ^ w5_t), 1u); SHA1_STEP (SHA1_F1, d, e, a, b, c, w5_t);
  w6_t = rotl32 ((w3_t ^ we_t ^ w8_t ^ w6_t), 1u); SHA1_STEP (SHA1_F1, c, d, e, a, b, w6_t);
  w7_t = rotl32 ((w4_t ^ wf_t ^ w9_t ^ w7_t), 1u); SHA1_STEP (SHA1_F1, b, c, d, e, a, w7_t);

  #undef K
  #define K SHA1C02

  w8_t = rotl32 ((w5_t ^ w0_t ^ wa_t ^ w8_t), 1u); SHA1_STEP (SHA1_F2o, a, b, c, d, e, w8_t);
  w9_t = rotl32 ((w6_t ^ w1_t ^ wb_t ^ w9_t), 1u); SHA1_STEP (SHA1_F2o, e, a, b, c, d, w9_t);
  wa_t = rotl32 ((w7_t ^ w2_t ^ wc_t ^ wa_t), 1u); SHA1_STEP (SHA1_F2o, d, e, a, b, c, wa_t);
  wb_t = rotl32 ((w8_t ^ w3_t ^ wd_t ^ wb_t), 1u); SHA1_STEP (SHA1_F2o, c, d, e, a, b, wb_t);
  wc_t = rotl32 ((w9_t ^ w4_t ^ we_t ^ wc_t), 1u); SHA1_STEP (SHA1_F2o, b, c, d, e, a, wc_t);
  wd_t = rotl32 ((wa_t ^ w5_t ^ wf_t ^ wd_t), 1u); SHA1_STEP (SHA1_F2o, a, b, c, d, e, wd_t);
  we_t = rotl32 ((wb_t ^ w6_t ^ w0_t ^ we_t), 1u); SHA1_STEP (SHA1_F2o, e, a, b, c, d, we_t);
  wf_t = rotl32 ((wc_t ^ w7_t ^ w1_t ^ wf_t), 1u); SHA1_STEP (SHA1_F2o, d, e, a, b, c, wf_t);
  w0_t = rotl32 ((wd_t ^ w8_t ^ w2_t ^ w0_t), 1u); SHA1_STEP (SHA1_F2o, c, d, e, a, b, w0_t);
  w1_t = rotl32 ((we_t ^ w9_t ^ w3_t ^ w1_t), 1u); SHA1_STEP (SHA1_F2o, b, c, d, e, a, w1_t);
  w2_t = rotl32 ((wf_t ^ wa_t ^ w4_t ^ w2_t), 1u); SHA1_STEP (SHA1_F2o, a, b, c, d, e, w2_t);
  w3_t = rotl32 ((w0_t ^ wb_t ^ w5_t ^ w3_t), 1u); SHA1_STEP (SHA1_F2o, e, a, b, c, d, w3_t);
  w4_t = rotl32 ((w1_t ^ wc_t ^ w6_t ^ w4_t), 1u); SHA1_STEP (SHA1_F2o, d, e, a, b, c, w4_t);
  w5_t = rotl32 ((w2_t ^ wd_t ^ w7_t ^ w5_t), 1u); SHA1_STEP (SHA1_F2o, c, d, e, a, b, w5_t);
  w6_t = rotl32 ((w3_t ^ we_t ^ w8_t ^ w6_t), 1u); SHA1_STEP (SHA1_F2o, b, c, d, e, a, w6_t);
  w7_t = rotl32 ((w4_t ^ wf_t ^ w9_t ^ w7_t), 1u); SHA1_STEP (SHA1_F2o, a, b, c, d, e, w7_t);
  w8_t = rotl32 ((w5_t ^ w0_t ^ wa_t ^ w8_t), 1u); SHA1_STEP (SHA1_F2o, e, a, b, c, d, w8_t);
  w9_t = rotl32 ((w6_t ^ w1_t ^ wb_t ^ w9_t), 1u); SHA1_STEP (SHA1_F2o, d, e, a, b, c, w9_t);
  wa_t = rotl32 ((w7_t ^ w2_t ^ wc_t ^ wa_t), 1u); SHA1_STEP (SHA1_F2o, c, d, e, a, b, wa_t);
  wb_t = rotl32 ((w8_t ^ w3_t ^ wd_t ^ wb_t), 1u); SHA1_STEP (SHA1_F2o, b, c, d, e, a, wb_t);

  #undef K
  #define K SHA1C03

  wc_t = rotl32 ((w9_t ^ w4_t ^ we_t ^ wc_t), 1u); SHA1_STEP (SHA1_F1, a, b, c, d, e, wc_t);
  wd_t = rotl32 ((wa_t ^ w5_t ^ wf_t ^ wd_t), 1u); SHA1_STEP (SHA1_F1, e, a, b, c, d, wd_t);
  we_t = rotl32 ((wb_t ^ w6_t ^ w0_t ^ we_t), 1u); SHA1_STEP (SHA1_F1, d, e, a, b, c, we_t);
  wf_t = rotl32 ((wc_t ^ w7_t ^ w1_t ^ wf_t), 1u); SHA1_STEP (SHA1_F1, c, d, e, a, b, wf_t);
  w0_t = rotl32 ((wd_t ^ w8_t ^ w2_t ^ w0_t), 1u); SHA1_STEP (SHA1_F1, b, c, d, e, a, w0_t);
  w1_t = rotl32 ((we_t ^ w9_t ^ w3_t ^ w1_t), 1u); SHA1_STEP (SHA1_F1, a, b, c, d, e, w1_t);
  w2_t = rotl32 ((wf_t ^ wa_t ^ w4_t ^ w2_t), 1u); SHA1_STEP (SHA1_F1, e, a, b, c, d, w2_t);
  w3_t = rotl32 ((w0_t ^ wb_t ^ w5_t ^ w3_t), 1u); SHA1_STEP (SHA1_F1, d, e, a, b, c, w3_t);
  w4_t = rotl32 ((w1_t ^ wc_t ^ w6_t ^ w4_t), 1u); SHA1_STEP (SHA1_F1, c, d, e, a, b, w4_t);
  w5_t = rotl32 ((w2_t ^ wd_t ^ w7_t ^ w5_t), 1u); SHA1_STEP (SHA1_F1, b, c, d, e, a, w5_t);
  w6_t = rotl32 ((w3_t ^ we_t ^ w8_t ^ w6_t), 1u); SHA1_STEP (SHA1_F1, a, b, c, d, e, w6_t);
  w7_t = rotl32 ((w4_t ^ wf_t ^ w9_t ^ w7_t), 1u); SHA1_STEP (SHA1_F1, e, a, b, c, d, w7_t);
  w8_t = rotl32 ((w5_t ^ w0_t ^ wa_t ^ w8_t), 1u); SHA1_STEP (SHA1_F1, d, e, a, b, c, w8_t);
  w9_t = rotl32 ((w6_t ^ w1_t ^ wb_t ^ w9_t), 1u); SHA1_STEP (SHA1_F1, c, d, e, a, b, w9_t);
  wa_t = rotl32 ((w7_t ^ w2_t ^ wc_t ^ wa_t), 1u); SHA1_STEP (SHA1_F1, b, c, d, e, a, wa_t);
  wb_t = rotl32 ((w8_t ^ w3_t ^ wd_t ^ wb_t), 1u); SHA1_STEP (SHA1_F1, a, b, c, d, e, wb_t);
  wc_t = rotl32 ((w9_t ^ w4_t ^ we_t ^ wc_t), 1u); SHA1_STEP (SHA1_F1, e, a, b, c, d, wc_t);
  wd_t = rotl32 ((wa_t ^ w5_t ^ wf_t ^ wd_t), 1u); SHA1_STEP (SHA1_F1, d, e, a, b, c, wd_t);
  we_t = rotl32 ((wb_t ^ w6_t ^ w0_t ^ we_t), 1u); SHA1_STEP (SHA1_F1, c, d, e, a, b, we_t);
  wf_t = rotl32 ((wc_t ^ w7_t ^ w1_t ^ wf_t), 1u); SHA1_STEP (SHA1_F1, b, c, d, e, a, wf_t);

  digest[0] += a;
  digest[1] += b;
  digest[2] += c;
  digest[3] += d;
  digest[4] += e;
}

void sha1_init (sha1_ctx_t *sha1_ctx)
{
  sha1_ctx->h[0] = SHA1M_A;
  sha1_ctx->h[1] = SHA1M_B;
  sha1_ctx->h[2] = SHA1M_C;
  sha1_ctx->h[3] = SHA1M_D;
  sha1_ctx->h[4] = SHA1M_E;

  sha1_ctx->w0[0] = 0;
  sha1_ctx->w0[1] = 0;
  sha1_ctx->w0[2] = 0;
  sha1_ctx->w0[3] = 0;
  sha1_ctx->w1[0] = 0;
  sha1_ctx->w1[1] = 0;
  sha1_ctx->w1[2] = 0;
  sha1_ctx->w1[3] = 0;
  sha1_ctx->w2[0] = 0;
  sha1_ctx->w2[1] = 0;
  sha1_ctx->w2[2] = 0;
  sha1_ctx->w2[3] = 0;
  sha1_ctx->w3[0] = 0;
  sha1_ctx->w3[1] = 0;
  sha1_ctx->w3[2] = 0;
  sha1_ctx->w3[3] = 0;

  sha1_ctx->len = 0;
}

void sha1_update_64 (sha1_ctx_t *sha1_ctx, u32x w0[4], u32x w1[4], u32x w2[4], u32x w3[4], const int len)
{
  const int pos = sha1_ctx->len & 0x3f;

  sha1_ctx->len += len;

  if ((pos + len) < 64)
  {
    switch_buffer_by_offset_be (w0, w1, w2, w3, pos);

    sha1_ctx->w0[0] |= w0[0];
    sha1_ctx->w0[1] |= w0[1];
    sha1_ctx->w0[2] |= w0[2];
    sha1_ctx->w0[3] |= w0[3];
    sha1_ctx->w1[0] |= w1[0];
    sha1_ctx->w1[1] |= w1[1];
    sha1_ctx->w1[2] |= w1[2];
    sha1_ctx->w1[3] |= w1[3];
    sha1_ctx->w2[0] |= w2[0];
    sha1_ctx->w2[1] |= w2[1];
    sha1_ctx->w2[2] |= w2[2];
    sha1_ctx->w2[3] |= w2[3];
    sha1_ctx->w3[0] |= w3[0];
    sha1_ctx->w3[1] |= w3[1];
    sha1_ctx->w3[2] |= w3[2];
    sha1_ctx->w3[3] |= w3[3];
  }
  else
  {
    u32x c0[4] = { 0 };
    u32x c1[4] = { 0 };
    u32x c2[4] = { 0 };
    u32x c3[4] = { 0 };

    switch_buffer_by_offset_carry_be (w0, w1, w2, w3, c0, c1, c2, c3, pos);

    sha1_ctx->w0[0] |= w0[0];
    sha1_ctx->w0[1] |= w0[1];
    sha1_ctx->w0[2] |= w0[2];
    sha1_ctx->w0[3] |= w0[3];
    sha1_ctx->w1[0] |= w1[0];
    sha1_ctx->w1[1] |= w1[1];
    sha1_ctx->w1[2] |= w1[2];
    sha1_ctx->w1[3] |= w1[3];
    sha1_ctx->w2[0] |= w2[0];
    sha1_ctx->w2[1] |= w2[1];
    sha1_ctx->w2[2] |= w2[2];
    sha1_ctx->w2[3] |= w2[3];
    sha1_ctx->w3[0] |= w3[0];
    sha1_ctx->w3[1] |= w3[1];
    sha1_ctx->w3[2] |= w3[2];
    sha1_ctx->w3[3] |= w3[3];

    sha1_transform (sha1_ctx->w0, sha1_ctx->w1, sha1_ctx->w2, sha1_ctx->w3, sha1_ctx->h);

    sha1_ctx->w0[0] = c0[0];
    sha1_ctx->w0[1] = c0[1];
    sha1_ctx->w0[2] = c0[2];
    sha1_ctx->w0[3] = c0[3];
    sha1_ctx->w1[0] = c1[0];
    sha1_ctx->w1[1] = c1[1];
    sha1_ctx->w1[2] = c1[2];
    sha1_ctx->w1[3] = c1[3];
    sha1_ctx->w2[0] = c2[0];
    sha1_ctx->w2[1] = c2[1];
    sha1_ctx->w2[2] = c2[2];
    sha1_ctx->w2[3] = c2[3];
    sha1_ctx->w3[0] = c3[0];
    sha1_ctx->w3[1] = c3[1];
    sha1_ctx->w3[2] = c3[2];
    sha1_ctx->w3[3] = c3[3];
  }
}

void sha1_update_local (sha1_ctx_t *sha1_ctx, const __local u32x *w, const int len)
{
  u32x w0[4];
  u32x w1[4];
  u32x w2[4];
  u32x w3[4];

  int i;
  int j;

  for (i = 0, j = 0; i < len - 64; i += 64, j += 16)
  {
    w0[0] = w[j +  0];
    w0[1] = w[j +  1];
    w0[2] = w[j +  2];
    w0[3] = w[j +  3];
    w1[0] = w[j +  4];
    w1[1] = w[j +  5];
    w1[2] = w[j +  6];
    w1[3] = w[j +  7];
    w2[0] = w[j +  8];
    w2[1] = w[j +  9];
    w2[2] = w[j + 10];
    w2[3] = w[j + 11];
    w3[0] = w[j + 12];
    w3[1] = w[j + 13];
    w3[2] = w[j + 14];
    w3[3] = w[j + 15];

    sha1_update_64 (sha1_ctx, w0, w1, w2, w3, 64);
  }

  w0[0] = w[i +  0];
  w0[1] = w[i +  1];
  w0[2] = w[i +  2];
  w0[3] = w[i +  3];
  w1[0] = w[i +  4];
  w1[1] = w[i +  5];
  w1[2] = w[i +  6];
  w1[3] = w[i +  7];
  w2[0] = w[i +  8];
  w2[1] = w[i +  9];
  w2[2] = w[i + 10];
  w2[3] = w[i + 11];
  w3[0] = w[i + 12];
  w3[1] = w[i + 13];
  w3[2] = w[i + 14];
  w3[3] = w[i + 15];
  sha1_update_64 (sha1_ctx, w0, w1, w2, w3, len & 0x3f);
}

void sha1_update (sha1_ctx_t *sha1_ctx, const u32x *w, const int len)
{
  u32x w0[4];
  u32x w1[4];
  u32x w2[4];
  u32x w3[4];

  int i;
  int j;

  for (i = 0, j = 0; i < len - 64; i += 64, j += 16)
  {
    w0[0] = w[j +  0];
    w0[1] = w[j +  1];
    w0[2] = w[j +  2];
    w0[3] = w[j +  3];
    w1[0] = w[j +  4];
    w1[1] = w[j +  5];
    w1[2] = w[j +  6];
    w1[3] = w[j +  7];
    w2[0] = w[j +  8];
    w2[1] = w[j +  9];
    w2[2] = w[j + 10];
    w2[3] = w[j + 11];
    w3[0] = w[j + 12];
    w3[1] = w[j + 13];
    w3[2] = w[j + 14];
    w3[3] = w[j + 15];

    sha1_update_64 (sha1_ctx, w0, w1, w2, w3, 64);
  }

  w0[0] = w[i +  0];
  w0[1] = w[i +  1];
  w0[2] = w[i +  2];
  w0[3] = w[i +  3];
  w1[0] = w[i +  4];
  w1[1] = w[i +  5];
  w1[2] = w[i +  6];
  w1[3] = w[i +  7];
  w2[0] = w[i +  8];
  w2[1] = w[i +  9];
  w2[2] = w[i + 10];
  w2[3] = w[i + 11];
  w3[0] = w[i + 12];
  w3[1] = w[i + 13];
  w3[2] = w[i + 14];
  w3[3] = w[i + 15];

  sha1_update_64 (sha1_ctx, w0, w1, w2, w3, len & 0x3f);
}

void sha1_final (sha1_ctx_t *sha1_ctx)
{
  int pos = sha1_ctx->len & 0x3f;

  append_0x80_4x4 (sha1_ctx->w0, sha1_ctx->w1, sha1_ctx->w2, sha1_ctx->w3, pos ^ 3);
  if (pos >= 56)
  {
    sha1_transform (sha1_ctx->w0, sha1_ctx->w1, sha1_ctx->w2, sha1_ctx->w3, sha1_ctx->h);

    sha1_ctx->w0[0] = 0x0;
    sha1_ctx->w0[1] = 0;
    sha1_ctx->w0[2] = 0;
    sha1_ctx->w0[3] = 0;
    sha1_ctx->w1[0] = 0;
    sha1_ctx->w1[1] = 0;
    sha1_ctx->w1[2] = 0;
    sha1_ctx->w1[3] = 0;
    sha1_ctx->w2[0] = 0;
    sha1_ctx->w2[1] = 0;
    sha1_ctx->w2[2] = 0;
    sha1_ctx->w2[3] = 0;
    sha1_ctx->w3[0] = 0;
    sha1_ctx->w3[1] = 0;
    sha1_ctx->w3[2] = 0;
    sha1_ctx->w3[3] = 0;
  }

  sha1_ctx->w3[3] = sha1_ctx->len * 8;

  sha1_transform (sha1_ctx->w0, sha1_ctx->w1, sha1_ctx->w2, sha1_ctx->w3, sha1_ctx->h);
}